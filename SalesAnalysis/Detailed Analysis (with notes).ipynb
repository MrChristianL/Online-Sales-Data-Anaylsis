{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07b561de-2202-4d93-a7c7-8edc044e54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a958439-b739-4860-b986-5a318e2ca131",
   "metadata": {},
   "source": [
    "#### Merging 12 months of sales data into a single file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d32f1d4-c2be-4265-b3d7-0ce1792b279f",
   "metadata": {},
   "source": [
    "Below is how you read a single csv file into the notebook using Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d277ac4-42e2-47f3-8199-2dbf6c20add1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Quantity Ordered</th>\n",
       "      <th>Price Each</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Purchase Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176558</td>\n",
       "      <td>USB-C Charging Cable</td>\n",
       "      <td>2</td>\n",
       "      <td>11.95</td>\n",
       "      <td>04/19/19 08:46</td>\n",
       "      <td>917 1st St, Dallas, TX 75001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176559</td>\n",
       "      <td>Bose SoundSport Headphones</td>\n",
       "      <td>1</td>\n",
       "      <td>99.99</td>\n",
       "      <td>04/07/19 22:30</td>\n",
       "      <td>682 Chestnut St, Boston, MA 02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176560</td>\n",
       "      <td>Google Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>04/12/19 14:38</td>\n",
       "      <td>669 Spruce St, Los Angeles, CA 90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176560</td>\n",
       "      <td>Wired Headphones</td>\n",
       "      <td>1</td>\n",
       "      <td>11.99</td>\n",
       "      <td>04/12/19 14:38</td>\n",
       "      <td>669 Spruce St, Los Angeles, CA 90001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Order ID                     Product Quantity Ordered Price Each  \\\n",
       "0   176558        USB-C Charging Cable                2      11.95   \n",
       "1      NaN                         NaN              NaN        NaN   \n",
       "2   176559  Bose SoundSport Headphones                1      99.99   \n",
       "3   176560                Google Phone                1        600   \n",
       "4   176560            Wired Headphones                1      11.99   \n",
       "\n",
       "       Order Date                      Purchase Address  \n",
       "0  04/19/19 08:46          917 1st St, Dallas, TX 75001  \n",
       "1             NaN                                   NaN  \n",
       "2  04/07/19 22:30     682 Chestnut St, Boston, MA 02215  \n",
       "3  04/12/19 14:38  669 Spruce St, Los Angeles, CA 90001  \n",
       "4  04/12/19 14:38  669 Spruce St, Los Angeles, CA 90001  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Sales_Data/Sales_April_2019.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9cbb0-45b2-4034-93a4-efbd5d2fc823",
   "metadata": {},
   "source": [
    "But what if you wanted to save time and read all csv files into the notebook? Do you have to have 12 lines of pd.read_csv?\n",
    "\n",
    "There is almost always an easier, more succinct way to perform a task. Don't be afraid to Google something to find a shorter, better way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4bcfd98-cd22-4598-9e22-a85433c7aea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".Sales_December_2019.csv.icloud\n",
      "Sales_April_2019.csv\n",
      "Sales_August_2019.csv\n",
      "Sales_February_2019.csv\n",
      "Sales_January_2019.csv\n",
      "Sales_July_2019.csv\n",
      "Sales_June_2019.csv\n",
      "Sales_March_2019.csv\n",
      "Sales_May_2019.csv\n",
      "Sales_November_2019.csv\n",
      "Sales_October_2019.csv\n",
      "Sales_September_2019.csv\n"
     ]
    }
   ],
   "source": [
    "files =  [file for file in os.listdir('./Sales_Data')]\n",
    "\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a010e4-d494-4e9d-9c87-fb51cc852130",
   "metadata": {},
   "source": [
    "Now that we have all our files, we need to determine how to merge (or concatenate) them into a single .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cbc96a5-f2b6-4d0c-a9a6-3f9fdb64f35f",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd3 in position 8: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m files \u001b[38;5;241m=\u001b[39m  [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Sales_Data\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m----> 6\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./Sales_Data/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     all_months_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([all_months_data, df])\n\u001b[0;32m      9\u001b[0m all_months_data\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:548\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:637\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:848\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:859\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:2017\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd3 in position 8: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# define an empty df to store our data:\n",
    "all_months_data = pd.DataFrame()\n",
    "\n",
    "files =  [file for file in os.listdir('./Sales_Data')]\n",
    "for file in files:\n",
    "    df = pd.read_csv('./Sales_Data/' + file)\n",
    "    all_months_data = pd.concat([all_months_data, df])\n",
    "\n",
    "all_months_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07760635-8c4c-4d34-b3ec-6caa58698b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_months_data.to_csv('all_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda7f12-aa4a-4a8b-a318-5f1330c8283c",
   "metadata": {},
   "source": [
    "#### Read in updated dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe9a95-560b-4b7d-9596-e6d589bb14f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('all_data.csv')\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590490ec-a489-4356-af62-9ff00b2a0d9f",
   "metadata": {},
   "source": [
    "##### **QUESTION 1: What was the best month for sales? How much was earned in that month?**\n",
    "\n",
    "**Answer:** The best month for sales is December. This is likely due to the occurrence of Christmas during the month of December -- the largest shopping holiday in the United States, annually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662336c-873e-4c81-a0d2-e0b1a3839d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9063738c-9c0b-429c-961e-b00469dc9a76",
   "metadata": {},
   "source": [
    "To find the total money earned for each month, we must calculate the total income received for each sale, then add it up for each month.\n",
    "\n",
    "We can do this as follows:\n",
    "- earned = price each * quantity of item [Done]\n",
    "- sum of earned for each month\n",
    "- max(sum_earned) = best month\n",
    "\n",
    "Problems encountered:\n",
    "- There exist some values that are NaN\n",
    "- There exist columns that are just the column names reiterated for the sake of readability. This causes some calculations to be unable to be performed, resulting in errors.\n",
    "- The digits shown in the columns are actually strings, not floats or ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee6047-abc5-47fa-9de0-a5449f616b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([all_data['Quantity Ordered'], all_data['Price Each'], \n",
    "                   all_data['Order Date']])\n",
    "df = np.transpose(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e490e5-8388-45ca-8173-b55afc9874a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f974169-c4ff-481e-bca3-1a5a6f8470d5",
   "metadata": {},
   "source": [
    "Next, we must drop the rows that only contain the column heading repeated for readability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0697311c-cf14-4b41-ad5f-5d1fc1e8e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously did it as follows:\n",
    "''' for i in range(len(df['Quantity Ordered'])):\n",
    "       if df['Quantity Ordered'][i] == 'Quantity Ordered':\n",
    "          df.drop(i, inplace=True) '''\n",
    "\n",
    "# the following does the same, but is much faster and shorter\n",
    "df = df[df['Quantity Ordered'].str[:2] != 'Qu']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c0d4f5-c9b4-48da-9064-d39211f84f28",
   "metadata": {},
   "source": [
    "The above removes all entries in the DataFrame that are just the names of the column headers. This is to allow for the necessary multiplication for each month to be had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e5375-08bd-4298-9ac3-7e9a638869fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a63f91-0a77-46c8-821e-26739815dcb2",
   "metadata": {},
   "source": [
    "Since the rows that show up as NaN are just blank rows across all columns for the data set, we can drop them entirely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e9d86-e6eb-46d6-8b9a-607f55810660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35ef9e-3d91-4320-8927-fcef0a326a6f",
   "metadata": {},
   "source": [
    "Now that 'Quantity Ordered' contains just digits, we must change them from Str to Floats so that we can perform arithmetic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a9925f-9d3a-4e59-aba8-eb4893412236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quantity Ordered'] = pd.to_numeric(df['Quantity Ordered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0a1be-ac38-4547-9794-d7df8d99f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1c532a-3167-4457-9b10-3cca24c02d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price Each'] = pd.to_numeric(df['Price Each'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b118a8-5e99-4992-8cdf-6759b42f1047",
   "metadata": {},
   "source": [
    "We must now do the same for the 'Price Each' Series. However, since we used .drop(inplace=True) previously, we don't have to repeat the step where we delete the column headings for this Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af3ee22-8513-4ed0-a3b8-1458be0bcb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Earned'] = df['Quantity Ordered'] * df['Price Each']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3707b3-1ddb-4d44-ab6e-6b88839eee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99663b0-56a9-4c4e-b7e6-454f21ad9587",
   "metadata": {},
   "source": [
    "In order to more easily navigate the dataFrame, it is important to reset the indexes of the dataFrame so that it doesn't skip values (0, 1, 2... instead of 0, 2, 3...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e04c3-2022-4a58-9b4a-30a63c9c4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178944ac-cbdf-4d17-8b21-07d53ee5fd88",
   "metadata": {},
   "source": [
    "Now that we have the total amount earned for each sale, we must determine how much was earned per month. To do this, we must first identify the month that each purchase occured in, then we must sum all values in the 'Earned' column during that time.\n",
    "\n",
    "Using a comprehension within a series, we're able to cut just the month portion of the order date off to add it to the new Month column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52968ece-0b67-4c6e-a4d7-51fb08203e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Month'] = pd.Series([df['Order Date'][i][:2] for i in range(len(df['Order Date']))])\n",
    "\n",
    "df['Month'] = pd.to_numeric(df['Order Date'].str[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c722e9-29e4-4950-9625-f38cdd0ef509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month'].unique() #ensure it's only the months and that all months are represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ce899-cbb0-4115-af73-5fe7e93afac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [sum(df['Earned'][i]) for i in df['Month'] if i == '04']\n",
    "\n",
    "sales_per_month = df.groupby('Month').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b501a65-d557-4582-82de-a8cecf01bdcd",
   "metadata": {},
   "source": [
    "Now that we have our total sales per month (in USD earned), we can now graph the outcome to better view the data and answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd8c19-6c45-4481-8a60-39e0bd2e22f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4945d4bb-43d9-4758-8c70-2311967fb195",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = np.arange(1, 13)\n",
    "\n",
    "plt.figure(figsize = (10, 6))\n",
    "\n",
    "plt.plot(months, sales_per_month['Earned'])\n",
    "plt.xticks(months)\n",
    "\n",
    "plt.xlabel('Months')\n",
    "plt.ylabel('Sales Per Month in Millions ($USD)')\n",
    "plt.title('Monthly Sales Nation-wide (2019)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347a664c-45ec-458b-8a87-d3f5cdafc203",
   "metadata": {},
   "source": [
    "##### **QUESTION 2: What city sold the most products?**\n",
    "\n",
    "**Answer:** The city that sold the most products (and earned the most in sales) is San Fransisco. This could be due to the overall population, the high frequency of technical work that may require more expensive products such as laptops, the average income within Silicon Valley that allows for more spending, etc. Similarly, the graph shows that the cities that sold the most products earned the most income, and vice versa. This shows that there aren't cities that are buying any more expensive products, but fewer products total, than any other city -- within this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cd5625-a08d-490f-b2a6-a329cc03ba13",
   "metadata": {},
   "source": [
    "In order to find the city that sold the most, we must split the data into the cities (and states), then sum up the sales that occurred in that city, similarly to how we did for the months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24b872-a525-4175-87e1-8748f8fa67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0244fd0c-9bbb-4a6d-85c6-444e7afeb118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb31c3f-2d8f-4627-8362-36b33779cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.Series(all_data['Purchase Address'][all_data['Purchase Address'].str[:1] != 'P'])\n",
    "temp.dropna(inplace=True)\n",
    "df['City'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c7dd11-196a-4bfb-94cf-5a5e4752b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This caused so many issues. Be sure to include 'drop = True', or else it won't work. It kept forcing NaN values back in.\n",
    "\n",
    "df['City'] = temp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891636d8-04e6-487b-8594-a9fdc33bc3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9ec21-1936-4741-87fa-e20a8828932e",
   "metadata": {},
   "source": [
    "###### Using the **.apply( )** method to identify cities and states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc424968-31b8-4943-a889-d0fdb85eed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_state(address):\n",
    "    city = address.split(',')[1]\n",
    "    state = address.split(',')[2].split(' ')[1]\n",
    "    return f'{city} ({state})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4ad54b-4c7c-4138-a8ff-11964c6e0c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = '669 Spruce St, Los Angeles, CA 90001'\n",
    "\n",
    "get_city_state(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de238d62-c816-4033-ac75-77dc1218f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['City'] = df['City'].apply(lambda x: get_city_state(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd88c9a-8fe6-470c-97c2-77911ad0198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f0614-2516-4b11-ab0b-97555b9b3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = df.groupby('City').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6864efb8-e075-4a7e-a2c2-03e0a8d72846",
   "metadata": {},
   "source": [
    "From this, we can see that San Fransisco bought the most products, as well as earned the most in sales.\n",
    "\n",
    "To plot this, we need to have a list of just the unique values of the cities available. However, just using the .unique() method would cause the cities to change order form the list above. In order to remedy this, we can use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceef1ec-407d-43ee-b102-e3d8bacd06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [city for city, result in df.groupby('City')] # a list comprehension for the elements in the .groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db860b7-d59f-4945-b5d1-89044ff4d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (12, 6))\n",
    "\n",
    "plt.bar(cities, results['Quantity Ordered'], label='Number of Products Ordered')\n",
    "plt.xticks(cities, rotation='vertical', size=8)\n",
    "plt.xlabel('Cities')\n",
    "plt.ylabel('Products Ordered')\n",
    "plt.title('Products Ordered Per City')\n",
    "\n",
    "plt.plot(cities, results['Earned']/100, ':og', label='Earned in $10,000')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2fa4df-2bc3-4ad7-8b5e-32d83a9f594e",
   "metadata": {},
   "source": [
    "##### **QUESTION 3: What time should we display advertisements to maximize the likelihood of customers buying products?**\n",
    "\n",
    "**Answer:** The best time to show ads is during either 12:00 pm or 11:00 pm, as these are the times that the most orders are placed. This will increase the chances of ads being seen, as this means this is the time that the most active users are interacting with the website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7a1446-3e40-4b85-8582-ad7b1a9875b6",
   "metadata": {},
   "source": [
    "In order to figure out the best time to display adds, we need to determine what time of day most orders are processed. This involves determining the orders by order ID and the time of day (hour, minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd56a63-3840-41eb-b39e-a1e6f0b35fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders = pd.DataFrame({\n",
    "    'Order ID': all_data['Order ID'],\n",
    "    'When Occured': all_data['Order Date'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9440e9a-2501-4283-aa38-3f1a617a6774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders = df_orders[df_orders['Order ID'].str[:1] != 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99726d3a-f310-484b-8b3f-dc27b230ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders.dropna(inplace=True)\n",
    "df_orders = df_orders.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59213ad1-acc3-4b11-9aee-24c1975a24f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders['When Occured'] = pd.to_datetime(df_orders['When Occured'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350d364-618f-4cdd-9124-c77f911fbd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders['Hours'] = df_orders['When Occured'].dt.hour\n",
    "df_orders['Min'] = df_orders['When Occured'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8be815-5d3b-44dd-9792-7b0e4d39b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57415d4-5ce3-4dda-9532-f5a5cb9e70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = np.arange(0, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba7ebe-bc58-4fc0-a425-1de14df883d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = df_orders.groupby(['Hours']).count()['Order ID']\n",
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2827dc-0fe1-428b-b537-507adb935ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.plot(hours, orders)\n",
    "plt.xticks(hours)\n",
    "\n",
    "plt.title('Purchases Throughout The Day')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e524a562-ddd1-4185-979f-7b78f2332d0e",
   "metadata": {},
   "source": [
    "##### **QUESTION 4: What products are most often sold together?**\n",
    "\n",
    "**Answer:** The top 3 products that are most often purchased together are:\n",
    "1. An iPhone & a Lightning Charging Cable: 1005 occurances\n",
    "2. A Google Phone and a USB-C Charging Cable: 987 occurances\n",
    "3. An iPhone and a set of Wired Headphones: 447 occurances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972f933-e082-489b-b705-ede8c2232fd3",
   "metadata": {},
   "source": [
    "In order to find out which products most often sold together, we need to look for entries that share the same order ID, meaning that they were purchased at the same time. This will involve the product item name and order ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe79ff-323e-4d83-9e12-32fa268d6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_together = pd.DataFrame({\n",
    "    'Order': all_data['Order ID'],\n",
    "    'Product': all_data['Product']\n",
    "})\n",
    "\n",
    "df_together.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2693e892-2c33-4e05-ba61-ddd2dcd24038",
   "metadata": {},
   "source": [
    "The below is used each time to drop:\n",
    "1. The rows that are just the column names\n",
    "2. Blank rows (NaN entry rows)\n",
    "3. Reset the index of the dataFrame so that it is sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e1af46-af8d-45a6-8c9b-924e6dfd6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_together = df_together[df_together['Order'].str[:1] != 'O']\n",
    "df_together.dropna(inplace=True)\n",
    "df_together = df_together.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3033a26a-fcff-4ec6-8acf-d38e069c7ab0",
   "metadata": {},
   "source": [
    "For this data set, we know it is sufficiently cleaned when the x axis of the shape is 185,950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a429c1ff-3ce2-43fb-83e4-b0adfd8c9372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_together.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720111a3-2970-4563-bcd7-5ed7a47bd49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_together.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d68947-ebb5-46b8-9518-c58a28ea22ee",
   "metadata": {},
   "source": [
    "Now that we have the order # and the product, we need to look for duplicate order numbers to identify which products where most often purchased together. Once identified, we can put these products on the same row so as the order number so that we know they were purchased together;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39320fd3-abbb-4315-ad1b-c60fa86d4806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# together = product in product if order is duplicated()\n",
    "\n",
    "df_together['Order'].duplicated(keep=False) #keep = False marks all as duplicates, not just the first or last ones\n",
    "df_together['Grouped'] = df_together.groupby(['Order'])['Product'].transform(lambda x: ', '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0913dc-edfa-4d64-bc46-3e012bc2d489",
   "metadata": {},
   "source": [
    "###### ***NOTE:*** If you're ever looking for a quick way to find more info about something, such as \"keep = False\" or \".transform( )\", you can use Shift + Tab to bring up a document window that will explain more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d1fc3-4dd0-41a1-801b-793ddc62da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_together = df_together[df_together['Order'].duplicated(keep=False)] #only keep rows with more than one purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd20f9c-58ae-451b-9b10-dc28da2a53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_together.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bdd640-9868-44c0-ada4-4fc8016746f6",
   "metadata": {},
   "source": [
    "Now that we have all orders grouped up, we need only one of each order to get an accurate count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4adadba-65aa-490a-a5bd-c711f13840fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_together = df_together[['Order', 'Grouped']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9193c5d3-6f31-475f-aa6b-afcdf02d581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_together.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d85d5-c86e-4bd3-b18d-a516a059b9eb",
   "metadata": {},
   "source": [
    "The last step is to count the occurances of the same products being grouped:\n",
    "\n",
    "By using itertools and collections, we can analyze this data deeper, including how many items were purchased at a time, the most and least common purchases, etc.\n",
    "\n",
    "This solution described in reference: https://stackoverflow.com/questions/52195887/counting-unique-pairs-of-numbers-into-a-python-dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5850f-39ef-4373-8110-1e0afb44331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d0d15-4040-45d4-9780-262ac0f2da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter()\n",
    "\n",
    "for row in df_together['Grouped']:\n",
    "    row_list = row.split(',')\n",
    "    count.update(Counter(combinations(row_list, 2))) # count the items in pairs of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b1fd1-0223-46f7-8736-76db0aa6bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count.most_common(6) # .most_common() is a method that comes with Counter from collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85092538-f3fc-4b7b-8a5b-304513a80ba5",
   "metadata": {},
   "source": [
    "##### **QUESTION 5: What products sold the most? Why do you think?**\n",
    "\n",
    "**Answer:** The highest selling products are items such as AAA or AA batteries, charging cables, etc. These items are cheap and relatively disposable. Batteries need to be replaced. It's not uncommon for individuals to have multiple charging cables or require a replacement cable should one get lost or damaged. These items are also significantly cheapter than other, more permenant products such as phones, computers, etc. Since this question is particularly concerned with how many of each product is purchased, it makes sense that the products that are cheap and often have to be replaced sell the most frequently. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900f926e-c4da-4d8c-982d-2d3bf33b42d8",
   "metadata": {},
   "source": [
    "In order to figure out which products sold the most, we need the following: \n",
    "- Product * Quantity Ordered = total products sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d281b07-e768-440c-b912-3a22ea76a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.DataFrame({\n",
    "    'Product': all_data['Product'],\n",
    "    'Number Sold': all_data['Quantity Ordered']\n",
    "})\n",
    "\n",
    "#clean the data\n",
    "df_total = df_total[df_total['Product'].str[:1] != 'P']\n",
    "df_total.dropna(inplace=True)\n",
    "df_total = df_total.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078639b7-d8e3-4e08-8905-ef6c646f334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c79b1-b715-40ee-b06d-43e4c38b5f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['Number Sold'] = pd.to_numeric(df_total['Number Sold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df005b-d880-4aab-90a1-e0e80192e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d87b8-2ded-4423-98ca-15395e187eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_sold = df_total.groupby(['Product']).sum()\n",
    "products_sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65148ca1-9e49-4d61-84f7-b998533efadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [product for product, result in df_total.groupby('Product')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3575261c-c728-4d9b-a4dc-5e2704642ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.plot(products, products_sold)\n",
    "plt.ylabel('Number Sold')\n",
    "plt.xlabel('Products')\n",
    "plt.xticks(products, rotation='vertical', size=8)\n",
    "plt.title('The Highest Selling Products')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec96a353-5cf1-4b49-b239-266e507b34ef",
   "metadata": {},
   "source": [
    "##### **BONUS QUESTION 6: What individual product makes us the most money?**\n",
    "\n",
    "**Answer:** As hypothesized with Question 5, the products that sell most frequently bring in a very small percentage of the overall money earned through sales. The product that makes the most, The MacBook Pro, is one of the lowest selling items in terms of units sold. Similarly, the AAA battery -- the item that sold the most -- is essentially the product that brings in the least amount of monetary value. \n",
    "\n",
    "Interestingly enough, the product that sold the least in Question 5 (the LG Washer and Dryer) also accounts for some of the lowest monetary sales. Perhaps this is due to better alternatives, pricing, or perhaps the appeal of a washer and dryer opposed to a MacBook Pro or Phone. It may also have something to do with the lifespan of a product such as a washer or dryer, requiring very infrequently replacement or upgrade in its entirety. This is an interesting result that could use further exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45bb80b-ceb3-4973-b47c-edb097680e04",
   "metadata": {},
   "source": [
    "In order to figure out which product makes us the most money, we need to determine how many of each product is sold (already done) and multiply that by its average price to determine how much in sales each product makes up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba9742d-554a-403b-b5c9-e781cd1e24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = pd.DataFrame({\n",
    "    'Item': df_total['Product'],\n",
    "    'Sales': df['Earned']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8604a1-dbd2-44da-a66e-03aee87e6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = df_sales.groupby(['Item']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a6be7f-516b-4e31-9b2f-e4e28273f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b71f9a-2f8b-4332-a0fa-f093fad8a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using products from above;\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.plot(products, sales)\n",
    "plt.xlabel('Products')\n",
    "plt.ylabel('Sales, in Millions ($USD)')\n",
    "plt.xticks(products, rotation='vertical', size=8)\n",
    "plt.title('The Products That Make The Most')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f834f4-4c65-46a3-b268-4f8728bb53eb",
   "metadata": {},
   "source": [
    "rowID, OrderId, date, customerID, customerName, segment(corporate, consumer, etc), city, state, country, product, category, sales, quantity, profit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
